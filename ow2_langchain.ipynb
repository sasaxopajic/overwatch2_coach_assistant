{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Overwatch 2 Coach chatbot helps users extract and explore video transcriptions to learn strategies, tips, and lore about their favorite Overwatch heroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing I do, is importing the Youtube loader \n",
    "\n",
    "# pip install --upgrade --quiet  youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import text splitter, because the videos can be up to 1 hour long so the transcripts will be large.\n",
    "\n",
    "# pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import OpenAI LLM for which I need an OPENAI_API_KEY that is stored as an environmental variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also need OpenAI embeddings.\n",
    "\n",
    "# pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import  LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using FAISS library for vector stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's load our local environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize embeddings without any parameters because I will be using variables from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I create vector database for the video transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_database_from_yt_url(video_url: str) -> FAISS:\n",
    "    # Load and transcript the youtube video    \n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcript = loader.load()\n",
    "\n",
    "    # Very large transcript of the video is being splitted into smaller chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "    # Initialize database. FAISS does similarity search\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_query(db, query, k=5):\n",
    "    # 4-o mini can handle up tp 8k tokens but I will send 5k\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    # Join all documents\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "    \n",
    "    # Set GPT to 4-mini\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4-mini\")\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variable=[\"question\", docs],\n",
    "        template=\"After watching the video, what are some key strategies and gameplay tips to effectively utilize this hero? Please include detailed strategies on positioning, optimal ability usage, and synergy with teammates. Discuss how to counter common enemy heroes and share tips for adapting to different map environments. Additionally, offer insights on improving overall gameplay mechanics with this hero, including decision-making during team fights and when to engage or disengage. Answer the following question: {question} By searching the following transcript: {docs}. Your answers should be detailed. Don't hallucinate. If you don't know the answer, simply say 'I don't know' \"\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    inputs = {\n",
    "    \"question\": query,\n",
    "    \"docs\": docs_page_content\n",
    "    }\n",
    "\n",
    "    response = chain.invoke(inputs)\n",
    "\n",
    "    return response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
